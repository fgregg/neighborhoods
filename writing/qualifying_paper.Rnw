\documentclass[12pt,letter]{article}
\title{Learning Who Your Neighbors Are}
\date{}
\author{}
\usepackage{amsmath}
\usepackage{url}
\usepackage{tikz}
\usepackage{adjustbox}
\usepackage{natbib}
\usepackage{endnotes}
\usepackage{setspace}
\usepackage{endfloat}
\doublespacing

\let\footnote=\endnote
\let\cite=\citep

\usetikzlibrary{arrows}
\usetikzlibrary{bayesnet}

\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\argmax}{\arg\!\max}

\begin{document}
\maketitle
<<include=FALSE>>=
library(xtable)
opts_chunk$set(echo=FALSE, 
               fig.width=4.5, 
               fig.height=4.75, 
               fig.align="center",
               fig.pos="h!",
               digits=2,
               fig.path='/home/fgregg/sweave-cache/figs/', 
               cache.path='/home/fgregg/sweave-cache/values/', 
               dev='tikz',
               cache=TRUE) 

inline_hook <- function(x) {
    if(is.numeric(x)) {
      x <- formatC(round(x, 2), big.mark=",", format="d")
      paste(x, collapse=", ")
    }
    else {
      x
    }
  }
knit_hooks$set(inline = inline_hook)
@


<<preamble, cache=FALSE>>= 
setwd('/home/fgregg/academic/neighborhoods/writing/')
default_margins = par("mar")
CURDIR <- "/home/fgregg/academic/neighborhoods/writing"
@ 

\section*{Introduction}
In the neighborhoods effect literature, neighborhoods face collective
action problems but vary in their abilities to respond. Neighborhoods
differ in their share of social goods and ills due, in part, to
neighbors' power to respond to their common concerns.

To understand how some neighbors' can coordinate an effective response
to common concerns while others cannot, we face a fundamental
methodological task: identifying the residents who have concerns in
common. We need to understand which residents count as relevant
co-actors, that is, which residents count as neighbors.

One possibility is that residents see their neighbors as those who
simply live nearby. If so, then the neighborhood facing collective
action problems is specific to each resident, and the ability for
neighbors to effectively respond to their common concerns can vary
continuously block-to-block.\footnote{The literature has tended
  towards this definition neighborhood, using smaller and smaller
  areal definitions of neighborhoods and continuous-space modeling
  strategies \cite{savitz_exploiting_2009}.}

If the collective action problem requires joint action between
neighbors, than this may be the right definition of neighborhoods. We
know that mere proximity is an important factor for forming
the real, personal social ties that can form the basis of further,
costly joint action \cite{hipp_simultaneous_2009, grannis_ground_2009}.

However, within the neighborhood effects literature, few of the
collective problems truly require joint action. Instead, the problems
depends upon individual's interdependent beliefs about their
neighbors. 

The classic example is the choice of a property owners to invest in a
property. People should invest in their property when they expect a
positive return, but their expectation is related to the perception
that others are investing \cite{taub_paths_1987}. Similarly, effective
informal social control, like intervening if kids are skipping school,
depends upon individual action influenced by beliefs about how others
would act.\cite{sampson_neighborhoods_1997}

For perception-based problems, we do not yet have a good understanding
of what area contains the perceived relevant co-actors.  The area may
well vary for different concerns. However, we can start with the areas
that residents perceive as their neighborhood. 

On occasion, urban sociologists have tried to identify neighborhoods
by asking residents to define them for us. What we have repeatedly
found is that individual residents are uncertain about the limits of
their neighborhood and that groups of residents will draw different
boundaries for the same neighborhood \cite{hunter_symbolic_1974, campbell_subjective_2009}.

However, all past surveys of neighborhood perception have had small
samples or been spread out over a large geographic area. If we had
sufficient, overlapping data, these vague and conflicting neighborhood
perceptions may average out to reveal that that different areas of a
city have a strong and distinct tendencies to be seen as different
neighborhoods.

In this paper, I discuss a novel Internet source for data on
neighborhood perception, demonstrate that this data coheres together,
and provide evidence that these differences in perception line up with
differences in the physical and social organization of different
areas. Further, I show how we can use these data to predict what areas
of a city are likely to be seen as distinct by residents even when we
don't have data on those resident's perceptions.

\section*{Neighborhood Claims}
Craigslist is the largest classified listing service. It
has about 60 million visitors each month from the United States. The
service is organized into more than 700 city specific sites. On a city
specific site, like \url{http://chicago.craigslist.org}, the
classified listings are organized into categories like ``Housing'' and 
subcategories like ``Sublets/Temporary.'' 

It is free to read the classified ads and free to post ads except for
a few subcategories. It is free to post in all the ``Housing''
categories except for brokered apartment rentals in New York City. 

Both private individuals and real estate companies use Craigslist to
advertise housing listings. However, the listings in the categories
for roommates, shared housing, sublets, are mainly made by
individuals. The listings for apartments are mainly made by landlords
both large and small. 

When an advertiser posts a housing listing on Craigslist they have the
option of putting in an address of the listing or a nearby street
intersection. If the advertiser puts in the geographic information,
she will be shown a map with a pin over the listing's location. If the
pin is not in the correct place, the advertiser can move the pin as
necessary. The advertiser can also put a pin in the desired location
without entering in address or street intersection information. When
the listing is published, the geographic coordinates of the posting
are embedded in the posting's web page.

In addition, to location of the listing, the advertiser also has the
option of filling out a field entitled ``Specific location.'' The
advertiser can put whatever text she wants to in this field, but
typically advertisers put in the name of a neighborhood. This
information is also embedded in the published listing.

If a housing listing has a neighborhood name in the ``Specific
location'' and the geographic coordinates of the listing location, the
listing represents a claim that a particular point in the city is part
of a neighborhood.

I have written a computer program that checks for and downloads, every
night, listings in the ``apts/housing'', ``rooms/shared'', and
``sublets/temporary'' subcategories for the following cities:

New York, Los Angeles, Houston, Philadelphia, Phoenix, San Antonio,
San Diego, Dallas, Jacksonville, Indianapolis, San Francisco, Austin,
Columbus, Charlotte, Detroit, El Paso, Memphis, Baltimore, Boston,
Seattle, Washington D.C., Nashville, Denver, Louisville, Milwaukee,
Portland, Las Vegas, Oklahoma City, Albuquerque, Tucson, Fresno,
Sacramento, Kansas City, Atlanta, Colorado Springs, Omaha, Raleigh,
Miami, Cleveland, Tulsa, Minneapolis, Wichita, Knoxville, Asheville

Another computer program parses the downloaded web page (a HTML
document) and extracts the geographic information and the contents of
the ``Specific location'' field. If the geographic coordinates are
missing, but address or street intersection information is available,
the program attempt to lookup the geographic coordinates associated with
this information using a geocoding service. (citation)

* information on how many posts
* how many claims


\subsection*{Data}
<<loadFeatures, include=FALSE, cache=FALSE>>= 
setwd('../code/training/')
source('features.R')
setwd(CURDIR)
@ 


I have a nightly updated database of geocoded Craigslist apartment
rentals, sublet, and roommate listings. For most of these listings,
the poster entered some text in a ``Specific Location'' field. With
some minimal pre-processing, we can use these data as observations of
claims that geographical points are in some neighborhood.

Using kernel density estimation, we can use this point data to
estimate a continuous probability distributions that any point in the
city will be claimed to be in any of the neighborhoods. 

At the center of every census block, we will calculate the most
probable neighborhood assignment and assign that most likely
neighborhood to that block. This will be our training data (Figure
\ref{fig:training}).

I would like to treat this measure as a kind of `averaged neighborhood
perception.' Of course, it is at best a biased measure of that
perception. There are enormous selection effect. Most of the
Craigslist listings come from the part of Chicago that have higher
fractions of young adults. Moreover, we are only considering listings
for roommates, sublets, and apartments. Portions of the city that are
dominated by owner occupants are underrepresented, because home sale
listings are excluded. Perhaps even more troublesome, the listers who
are on Craigslist sometimes claim neighborhoods strategically in order
to increase the desirability of their listing.

\input{theory_and_math.tex}



For our currently purpose of understanding this modeling
\emph{approach}, we can ignore these difficulties. In a future work,
when we use these models to make claims about how neighborhoods work,
we will take up this issue again.

\begin{figure}
<<plotTraining, dev='pdf', message=FALSE>>=
source('plot_training.R')
@ 
\caption{Training Data}
\label{fig:training}
\end{figure}


In addition to these data about neighborhood perception, we also have
block level census data as well as a trove of unaggregated data from
the City of Chicago on the built environment, crimes, 311 reports,
zoning, and the similar. We'd like to set them in relation to each
other.

\section*{Data Details}
The ultimate units of measurement are U.S. Census blocks and the edges
between them. The U.S. Census blocks mainly correspond to city face blocks.
We use a rook adjacency to define the edges, i.e. all edges are between blocks
that share a common border of length greater than 0. In the training data,
there are \Sexpr{dim(blocks.poly)[1]} blocks and
  \Sexpr{dim(features)[1]} edges.

For the inter-block similarities, we will use physical, demographic, and
administrative features (Table \ref{tab:Distribution}).

\subsection*{Physical Barriers}
Highways, rail lines, rivers, and major streets often act as neighborhood
boundaries. For each of these types of features, we code an edge feature
variable as 1 if the two adjacent blocks are separated by the feature or code
and 0 otherwise.

We also measure the difference in orientation between blocks. Blocks
are nearly all longer than they are wide, and we calculate the angle
of the longest side. For each pair of blocks, we calculate the
difference between the orientations of the blocks. We normalize the
difference to fall in $[0, 1]$. This measure was inspired by Vivien
Palmer's work on the persistent effect of primary settlements. 

In the late 1920s, Palmer argued that when a subdivision
of a city was originally opened for residential settlement, the
area would start out largely homogenous in its building stock
and population. This homogeneity would lead to the subdivision
maintaining a common fate through the history of the city. The
residents would tend to respond similarly to larger urban processes
and the building stock would tend to have the same patterns of
depreciation and reevaluation. The primary settlement should act as
atomic, spatial unit for urban processes.\cite{palmer_primary_1932}

When subdivision were originally laid out, the developers tended to
align the streets within their subdivision. Misalignment of blocks are
a rough measure of the where different subdivision meet. 

\subsection*{School Boundaries}
If two adjacent blocks are in different elementary school attendance boundary
then we code an edge feature with 1, 0 otherwise. Similar for high schools.

\subsection*{Demographic Features}
From the U.S. Census, we have block level information on race, age, family
structure, and housing ownership patterns. We can define measures between
blocks for these data.

We will use two measures for the demographic factors. The first is the
absolute difference. The second is the $\chi$ distance $\sqrt{
\frac{1}{2} \sum_i^d \frac{(x_i - y_i)^2}{x_i + y_i}}$, where $x_i$ is
the frequency of bin $i$ of the histogram $\mathbf{x}$ and similar for
$y_i$. This is just the square root of the familiar $\chi^2$ statistic. By
taking the square root, $\chi$ becomes a metric.\cite{pele_distance_2011}

For race, the distribution is the number people coded by the Census as
``Hispanic or Latino'', ``Not Hispanic or Latino : White alone'', ``Not Hispanic
or Latino : Black Alone'', and ``Not Hispanic or Latino : Asian alone.''

For age, we'll use the absolute difference between the log median age of
neighboring blocks.

For family structure, the distribution is of households with children
versus households without. 

For housing structure, the distribution is of housing units in the
rental market, housing market, or otherwise disposed. We also use the
absolute difference between the log median density of housing units.

Many blocks have no one living in them or only a handful. In such
cases, it makes little sense to compare demographic distributions. If
either adjacent blocks has fewer than 30 persons living in it, we do
not calculate the demographic differences. There are
\Sexpr{sum(features$all_sufficient)} edges where we calculate these
demographic similarities.

<<featureTable, results='asis', message=FALSE>>= 
feature_summary <- data.frame(sufficient.population=c(mean(features$all_sufficient), 
                                rep(NA, 5)),
                              rail = c(mean(features$rail), 
                                rep(NA, 5)),
                              highway = c(mean(features$highway), 
                                rep(NA, 5)),
                              water = c(mean(features$water), 
                                rep(NA, 5)),
                              elementary.school = c(mean(features$elementary_school), 
                                rep(NA, 5)),
                              high.school = c(mean(features$high_school), 
                                rep(NA, 5)),
                              grid.street = c(mean(features$grid_street), 
                                rep(NA, 5)),
                              block.angle=c(mean(features$block_angle), 
                                  quantile(features$block_angle)),
                              diff_units.js=c(mean(features$diff_housing_units[features$all_sufficient==1]), 
                                  
                                quantile(features$diff_housing_units[features$all_sufficient==1])),


                              age.js=c(mean(features$abs_age[features$all_sufficient==1]), 
                                  
                                quantile(features$abs_age[features$all_sufficient==1])),
                              race.js=c(mean(features$chi_ethnicity[features$all_sufficient==1]), 
                                quantile(features$chi_ethnicity[features$all_sufficient==1])),
                              housing.js=c(mean(features$chi_housing[features$all_sufficient==1]), 
                                quantile(features$chi_housing[features$all_sufficient==1])),
                              family.js=c(mean(features$chi_family[features$all_sufficient==1]), 
                                quantile(features$chi_family[features$all_sufficient==1]))
                              
                              )
feature_summary <- xtable(t(feature_summary),
                          caption="Distribution of Barriers and Distances",
                          label="tab:Distribution")
colnames(feature_summary) <- c("Mean", "Min", "25th Quant.", "Median", "75th Quant.", "Max")
row.names(feature_summary) <- c("Sufficient Population", "Rail", "Highway", 
                                "Water", "Elementary School", "High School", 
                                "Grid Street", "Block Angle", 
                                "Log Housing Density", "Log Median Age", 
                                "Ethnicity", "Housing", "Family")
print(feature_summary)
@ 

\begin{figure}
<<railImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$rail + 1])
@ 
\caption{Rail Lines}
\end{figure}

\begin{figure}
<<highwayImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$highway + 1])
@ 
\caption{Highways}
\end{figure}

\begin{figure}
<<gridImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$grid_street + 1])
@ 
\caption{Major Streets}
\end{figure}

\begin{figure}
<<waterImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$water + 1])
@ 
\caption{River}
\end{figure}

\begin{figure}
<<elementaryImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$elementary_school + 1])
@ 
\caption{Elementary School Attendance Boundaries}
\end{figure}

\begin{figure}
<<highschoolImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$high_school + 1])
@ 
\caption{High School Attendance Boundaries}
\end{figure}

\begin{figure}
<<sufficientImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$all_sufficient + 1])
@ 
\caption{Sufficient Population}
\end{figure}


\begin{figure}
<<blockAngleImage, dev='pdf'>>= 
plot(all_edges$lines, col=rgb(colorRamp(c("lightgrey", "red"))(features$block_angle)/255))
@ 
\caption{Difference in Block Orientation}
\end{figure}

\begin{figure}
<<<raceImage, dev='pdf'>>=
plot(all_edges$lines[features$all_sufficient==1], col=rgb(colorRamp(c("lightgrey", "red"), space="Lab")(M[,"all_sufficient:chi_ethnicity"][features$all_sufficient==1])/255))
@ 
\caption{Difference in Distribution of Race and Ethnicity}
\end{figure}


\begin{figure}
<<<ageImage, dev='pdf'>>=
plot(all_edges$lines[features$all_sufficient==1], col=rgb(colorRamp(c("lightgrey", "red"), space="Lab")(M[,"all_sufficient:abs_age"][features$all_sufficient==1]/max(M[,"all_sufficient:abs_age"]))/255))
@ 
\caption{Difference in Log Median Age}
\end{figure}


\begin{figure}
<<<housingDiffImage, dev='pdf'>>=
plot(all_edges$lines[features$all_sufficient==1], col=rgb(colorRamp(c("lightgrey", "red"), space="Lab")(M[,"all_sufficient:diff_housing_units"][features$all_sufficient==1]/max(M[,"all_sufficient:diff_housing_units"]))/255))
@ 
\caption{Difference in Log Density of Housing Units}
\end{figure}


\begin{figure}
<<<familyImage, dev='pdf'>>=
plot(all_edges$lines[features$all_sufficient==1], col=rgb(colorRamp(c("lightgrey", "red"), space="Lab")(M[,"all_sufficient:chi_family"][features$all_sufficient==1])/255))
@ 
\caption{Difference in Distribution of Family Type}
\end{figure}


\begin{figure}
<<<housingImage, dev='pdf'>>=
plot(all_edges$lines[features$all_sufficient==1], col=rgb(colorRamp(c("lightgrey", "red"), space="Lab")(M[,"all_sufficient:chi_housing"][features$all_sufficient==1])/255))
@ 
\caption{Difference in Distribution of Housing Type}
\end{figure}

\section*{Modeling}
Since many census blocks are empty, the demographic similarity between
these blocks is not well defined. We might be tempted to ignore these
cases, but deleting these cases would change the topology of the
city. Removing unpopulated blocks would turn populated blocks into
islands separated by commercial corridors. This would not allow for a
neighborhood to span a highway or industrial corridor, a possibility
we do not want to preclude.

We deal with this variation by using dummy variables to effectively
learn two model at once: a nonpopulated and populated block model.

Our overall scoring function is 
\begin{align}
&\operatorname{E}(\mathbf{y}, \mathbf{s}, \mathbf{w}) = \sum_{<i
    j>}^{\mathcal{N}}\epsilon_{i,j}(y_i, y_j, \mathbf{s}_{i,j}, \mathbf{w})  
\end{align}

where 
\begin{equation}
\epsilon_{i,j}(y_i, y_j, \mathbf{s}_{i,j}, \mathbf{w}) = \begin{cases}
    0 &y_i = y_j \\
    \phi(\mathbf{s}_{i,j}, \mathbf{w}) &y_i \neq y_j \\
  \end{cases}
\end{equation}

and the unpopulated block model is 
\begin{align}
\phi(\mathbf{s}_{i,j}, \mathbf{w}) = & w_0 
                                     + w_1\text{Rail}_{i,j} 
                                     + w_2\text{Water}_{i,j} 
                                     + w_3\text{Highway}_{i,j} \\
                                     &+ w_4\text{Major Street}_{i,j} 
                                     + w_5\text{Elementary School}_{i,j}\\ 
                                     & + w_6\text{High School}_{i,j}
                                     + w_7\text{Block Angle}_{i,j} \\
\end{align}

While the model for the populated neighboring blocks will be

\begin{align}
\phi(\mathbf{s}_{i,j}, \mathbf{w}) = & w_8 
                                     + w_9\text{Rail}_{i,j} 
                                     + w_{10}\text{Water}_{i,j} 
                                     + w_{11}\text{Highway}_{i,j}\\
                                     &+ w_{12}\text{Major Street}_{i,j} 
                                     + w_{13}\text{Elementary School}_{i,j}\\
                                     &+ w_{14}\text{High School}_{i,j} 
                                     + w_{15}\text{Block Angle}_{i,j}\\
                                     &+ w_{16}\text{Family Structure}_{i,j}
                                     + w_{17}\text{Race and Ethnicity}_{i,j}\\
                                     &+ w_{18}\text{Age Structure}_{i,j}  
                                     + w_{19}\text{Housing Structure}_{i,j} \\
                                     &+ w_{20}\text{Housing Density}_{i,j}  
\end{align}

We can combine these models by creating a dummy variable that takes a
value of 1 if neighboring blocks have sufficient population to support
the demographic distance measures, and 0 if the neighboring blocks do
not. We'll interact this dummy with the populated model and add the
variables to our unpopulated model.\footnote{Actually, our model is
  a little more complicated because we are not just comparing
  groups of people, but also groups of households and groups of
  housing units. Sometimes there is sufficient population to compare
  race, but not sufficient households to compare family structure. We
  use an additional dummy variables to handle these cases}

\begin{align}
\phi(\mathbf{s}_{i,j}, \mathbf{w}) =  & w_0 
                                     + w_1\text{Rail}_{i,j} 
                                     + w_2\text{Water}_{i,j} 
                                     + w_3\text{Highway}_{i,j} \\
                                     &+ w_4\text{Major Street}_{i,j} 
                                     + w_5\text{Elementary School}_{i,j}\\ 
                                     & + w_6\text{High School}_{i,j}
                                     + w_7\text{Block Angle}_{i,j} \\
                                     &+ \text{Populated Blocks}_{i,j}\cdot\\
                                     &\quad (w_8
                                     + w_{9}\text{Rail}_{i,j} 
                                     + w_{10}\text{Water}_{i,j}\\ 
                                     &\quad+ w_{11}\text{Highway}_{i,j}
                                     + w_{12}\text{Major Street}_{i,j}\\ 
                                     &\quad + w_{13}\text{Elementary School}_{i,j} 
                                     + w_{14}\text{High School}_{i,j}\\ 
                                     &\quad + w_{15}\text{Block Angle}_{i,j}
                                     + w_{16}\text{Family Structure}_{i,j}\\
                                     &\quad + w_{17}\text{Race and Ethnicity}_{i,j}
                                     + w_{18}\text{Age Structure}_{i,j}\\  
                                     &\quad+ w_{19}\text{Housing Structure}_{i,j}
                                     + w_{20}\text{Housing Density}_{i,j})\\
\end{align}


\section*{Results}
After training the model using the PyStruct structure learning
framework,\cite{mueller_pystruct:_2014} we get two classes of results:
predictions of Chicago neighborhoods and parameter
estimates.\footnote{See \url{https://github.com/fgregg/pystruct} for
  custom model} Given a set of learned weights we can find,
approximately, a lowest scoring assignment of labels to neighborhoods
of the city.\footnote{However, some care must be taken to not immediately
assign meaning to these labelings. Two blocks that have been assigned that
same label do not necessarily belong to the same neighborhood. The
labelings are only locally meaningful in that they distinguish a
particular neighborhood from it’s neighbors. Instead, a neighborhood
will be a set of blocks that have the same label and which are
connected components.}

Let’s start by looking at predictions for our training blocks to
highlight some characteristics of our model (Figure
\ref{fig:predictTraining}).

\begin{figure}
<<plotPredictions, echo=FALSE, dev='pdf', message=FALSE>>=
par(mfrow=c(1,2))
par(mar=rep(0, 4), xpd = NA) 
source('plot_training.R')
setwd('../code/training/')
source('plot_predictions.R')
setwd(CURDIR)
par(mfrow=c(1,1))
@ 
\caption{Predicted Neighborhoods}
\label{fig:predictTraining}
\end{figure}

<<RandIndex>>=

library(phyclust)
training_neighborhoods <- read.csv("../code/interchange/ks_label_semantic.csv")$x
infrequent <- hood_frequency[hoods] < 10
rand <- phyclust::RRand(hoods[!infrequent], training_neighborhoods[!infrequent])
@ 

First, our model depends upon C, the normalizer. We choose C by
estimating the model for various values of C between 1.0 and 0.0001
and choosing the value that maximizes the fit between the predicted
neighborhoods and the training neighborhoods. The value of C that gave
the best fit was 0.0005.

Second, our model predicts many, very small neighborhoods. In Figure
\ref{fig:predictTraining}, I have colored the
\Sexpr{sum(hood_frequency >= 10)} neighborhoods that have ten or more
blocks and grayed out the \Sexpr{sum(hood_frequency < 10)} remaining,
small neighborhoods. There are \Sexpr{sum(hood_frequency ==1)}
neighborhoods that consist of a single block.

Third, our model seems to do an adequate job in capturing
neighborhoods. We have a Rand Index score of \Sexpr{formatC(rand$Rand, format="f", digits=2)} and an
Adjusted Rand of \Sexpr{formatC(rand$adjRand, format="f", digits=2)}.

Now, turning to the parameters, we'll focus on the parameters for the
populated blocks (Table \ref{tab:parameters}). A positive parameter
means that, all else equal, the total score will be lower if adjacent
blocks are allocated to separate neighborhoods. Negative parameters,
means that all else equal, adjacent blocks should be allocated to the
same neighborhood. So, for example the negative intercepts mean that
adjacent blocks that are identical will ‘prefer’ to be assigned to the
same neighborhood.

Nearly all parameters for barriers and administrative zones have a
positive sign, which is what we expect: dissimilar blocks and blocks
separated by barriers are more apt to be placed in separate
neighborhoods. The negative `attractive' parameter for major street is
likely due to fact that every one of our training neighborhoods
contains multiple major grid streets.

The demographic distances are more complicated. Differences in ethnic
and racial composition is strongly positive. Such a `divisive'
parameter is required to have face validity in Chicago. Differences in
the density of housing units also has the expected sign. Differences
in median age and housing structure are unexpectedly weak, but also
very close to 0. The relatively strong `attractive' parameter for
differences in family structure is very surprising. According the this
model, a block that is all families and a block that has no families
are very apt to belong the same neighborhood. 

<<weightTable, results='asis', cache=FALSE>>=
setwd('../code/training/')
weights <- read.table("weights.csv")
names(weights) <- colnames(M)

no_pop <- c(weights[c('(Intercept)', 
                      'rail', 
                      'water',
                      'highway', 
                      'grid_street', 
                      'elementary_school', 
                      'high_school', 
                      'block_angle')])

pop <- c(weights[c('all_sufficient', 
                   'all_sufficient:rail', 
                   'all_sufficient:water',
                   'highway',
                   'all_sufficient:grid_street', 
                   'all_sufficient:elementary_school', 
                   'all_sufficient:high_school', 
                   'all_sufficient:block_angle')])
pop$highway <- 0

combined_pop <- c(as.numeric(pop) 
                  + as.numeric(no_pop), 
                  weights[c('all_sufficient:chi_family', 
                            'all_sufficient:chi_ethnicity', 
                            'all_sufficient:abs_age',
                            'all_sufficient:diff_housing_units',
                            'all_sufficient:chi_housing')])


models <- matrix(combined_pop)

rownames(models) <- c('(Intercept)', 
                      'Railroad', 
                      'Water', 
                      'Highway', 
                      'Major Street', 
                      'Elementary School', 
                      'High School', 
                      'Block Angle', 
                      'Family Structure', 
                      'Race and Ethnicity', 
                      'Age Structure', 
                      'Density of Housing Units',
                      'Housing Structure')

WT <- xtable(models, digits=4,
             caption="Parameter Estimates for Populated Blocks",
             label="tab:parameters")
colnames(WT) <- c("")

print(WT)

@ 

\section*{Discussion}
While these results of modeling neighborhoods are interesting, we
should take care to not put too much weight in them yet. Our purpose
in this paper is to explore an \emph{approach} to modeling
neighborhoods, and figuring out what counts block-by-block for making
a neighborhood.

What we have established is that this model of neighborhoods seems to
be able to predict, with some fidelity, the training data, and that
the parameter values comport with our previous expectations. These
results should give us confidence that the modeling approach can
capture this thing, the neighborhood, that we are trying to grasp.

However, in order to learn from the model or extrapolate 
predictions beyond the training data, this approach must pass much
more rigorous tests than simply predicting the training data for one
city. In a future paper, I will use this approach to model
neighborhoods in the fifty largest American urban areas, and evaluate
the predictive power of this conception of neighborhoods. 

In future work, we could use the same types of models to learn about
the structures of intra-party factions through looking at campaign
giving or social class-like structure by looking at marriage
patterns. Much of this work will depend upon being able to validly
distinguish between proximity and similarity. In cities, its easy to
do this. In other areas of social research, it's not so simple to
distinguish between the two.

\newpage
\begingroup
\parindent 0pt
\parskip 2ex
\def\enotesize{\normalsize}
\theendnotes
\endgroup

\newpage
\bibliographystyle{asr}
\bibliography{qp}

\begin{figure}
\includegraphics{../code/training/predicted_chicago_neighborhoods.pdf}
\caption{Predicted Neighborhoods in Chicago}
\end{figure}


\end{document}
