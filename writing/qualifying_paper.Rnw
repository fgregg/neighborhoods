\documentclass[12pt,letter]{article}
\usepackage{amsmath}
\usepackage{url}
\usepackage{tikz}
\usepackage{adjustbox}

\usetikzlibrary{arrows}
\usetikzlibrary{bayesnet}

\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\argmax}{\arg\!\max}

\begin{document}

<<include=FALSE>>=
library(xtable)
opts_chunk$set(echo=FALSE, 
               fig.width=4.5, 
               fig.height=4.75, 
               fig.align="center",
               fig.pos="h!",
               digits=2,
               fig.path='/home/fgregg/sweave-cache/figs/', 
               cache.path='/home/fgregg/sweave-cache/values/', 
               dev='tikz',
               cache=TRUE) 

inline_hook <- function(x) {
    if(is.numeric(x)) {
      x <- formatC(round(x, 2), big.mark=",", format="d")
      paste(x, collapse=", ")
    }
    else {
      x
    }
  }
knit_hooks$set(inline = inline_hook)
@


<<preamble, cache=FALSE>>= 
setwd('/home/fgregg/academic/neighborhoods/writing/')
default_margins = par("mar")
CURDIR <- "/home/fgregg/academic/neighborhoods/writing"
@ 



\section*{Introduction}
Social scientists have long been concerned with dividing the social
world into meaningful components. In recent year's we have
developed many methods to accomplish this when know what parts of the
world are similar to one another, broadly clustering, community
detection, and network partition techniques. Unfortunately, we are
seldom so lucky as to already know what really counts for making one
thing similar to another. 

When our similarity is binary, i.e. did ego nominate alter as friend,
life is easy. But, as soon as a variable has more than two possible
values then the researcher must choose, by hand, how to turn those
values into similarities. In the end, we adjust the various weights
until the groupings from our favorite clustering algorithm come out
looking about right. We would have been better off just drawing what
we wanted in the first place.

Another way is possible. If our subjects ever group themselves, we can
use that revealed grouping to learn what counts for similarity in a particular
social world. We can then apply our derived similarity to group elements in
a way that is likely to be meaningful to the types of people we learned from.

People group themselves in a variety of ways: making friends, getting
married, joining organizations, share consumption, and
self-labeling. In this paper, we will discuss a particular form of
self-labeling: claims that a location belongs to a city
neighborhood. However, the larger approach is much more general.

\input{theory_and_math.tex}

\section*{Results}
So much for theory, let's see how this works in practice. Let's take
the case of Chicago neighborhoods.  

\subsection*{Data}
<<loadFeatures, include=FALSE, cache=FALSE>>= 
setwd('../code/training/')
source('features.R')
setwd(CURDIR)
@ 


I have a nightly updated database of geocoded Craigslist apartment
rentals, sublet, and roommate listings. For most of these listings,
the poster entered some text in a ``Specific Location'' field. With
some minimal pre-processing, we can use these data as observations of
claims that geographical points are in some neighborhood.

Using kernel density estimation, we can use this point data to
estimate a continuous probability distributions that any point in the
city will be claimed to be in any of the neighborhoods. 

At the center of every census block, we will calculate the most
probable neighborhood assignment and assign that most likely
neighborhood to that block. This will be our training data (Figure
\ref{fig:training}).

I would like to treat this measure as a kind of `averaged neighborhood
perception.' Of course, it is at best a biased measure of that
perception. There are enormous selection effect. Most of the
Craigslist listings come from the part of Chicago that have higher
fractions of young adults. Moreover, we are only considering listings
for roommates, sublets, and apartments. Portions of the city that are
dominated by owner occupants are underrepresented, because home sale
listings are excluded. Perhaps even more troublesome, the listers who
are on Craigslist sometimes claim neighborhoods strategically in order
to increase the desirability of their listing.

However, I think it is possible that these data, biases and all, may
be good enough. We'll have ways of checking that hope.


\begin{figure}
<<plotTraining, dev='pdf', message=FALSE>>=
source('plot_training.R')
@ 
\caption{Training Data}
\label{fig:training}
\end{figure}

In addition to these data about neighborhood perception, we also have
block level census data as well as a trove of unaggregated data from
the City of Chicago on the built environment, crimes, 311 reports,
zoning, and the similar. We'd like to set them in relation to each
other.

\section*{Data Details}
The ultimate units of measurement are U.S. Census blocks and the edges
between them. The U.S. Census blocks mainly correspond to city face blocks.
We use a rook adjacency to define the edges, i.e. all edges are between blocks
that share a common border of length greater than 0. In the training data,
there are \Sexpr{dim(blocks.poly)[1]} blocks and
  \Sexpr{dim(features)[1]} edges.

For the inter-block similarities, we will use physical, demographic, and
administrative features (Table \ref{tab:Distribution}).

\subsection*{Physical Barriers}
Highways, rail lines, rivers, and major streets often act as neighborhood
boundaries. For each of these types of features, we code an edge feature
variable as 1 if the two adjacent blocks are separated by the feature or code
and 0 otherwise.

We also measure the difference in orientation between blocks. Blocks
are nearly all longer than they are wide, and we calculate the angle
of the longest side. For each pair of blocks, we calculate the
difference between the orientations of the blocks. We normalize the
difference to fall in $[0, 1]$. This measure was inspired by Vivien
Palmer's work on the persistent effect of primary settlements. 

In the late 1920s, Palmer developed the theory that when a subdivision
of a city was originally opened for residential settlement, the
area would start out largely homogenous in its building stock
and population. This homogeneity would lead to the subdivision
maintaining a common fate through the history of the city. The
residents would tend to respond similarly to larger urban processes
and the building stock would tend to have the same patterns of
depreciation and reevaluation.\cite{palmer_primary_1932}

When subdivision were originally platted, the developers tended to
align the streets within their subdivision. Misalignment of blocks are
a rough measure of the where different subdivision meet. 

\subsection*{School Boundaries}
If two adjacent blocks are in different elementary school attendance boundary
then we code an edge feature with 1, 0 otherwise. Similar for high schools.

\subsection*{Demographic Features}
From the U.S. Census, we have block level information on race, age, family
structure, and housing ownership patterns. We can define measures between
blocks for these data.

We will use two measures for the demographic factors. The first is the
absolute difference. The second is the $\chi$ distance $\sqrt{
\frac{1}{2} \sum_i^d \frac{(x_i - y_i)^2}{x_i + y_i}}$, where $x_i$ is
the frequency of bin $i$ of the histogram $\mathbf{x}$ and similar for
$y_i$. This is just the square root of the familiar $\chi^2$ statistic. By
taking the square root, $\chi$ becomes a metric.\cite{pele_distance_2011}

For race, the distribution is the number people coded by the Census as
``Hispanic or Latino'', ``Not Hispanic or Latino : White alone'', ``Not Hispanic
or Latino : Black Alone'', and ``Not Hispanic or Latino : Asian alone.''

For age, we'll use the absolute difference between the log median age of
neighboring blocks.

For family structure, the distribution is of households with children
versus households without. 

For housing structure, the distribution is of housing units in the
rental market, housing market, or otherwise disposed. We also use the
absolute difference between the log median density of housing units.

Many blocks have no one living in them or only a handful. In such
cases, it makes little sense to compare demographic distributions. If
either adjacent blocks has fewer than 30 persons living in it, we do
not calculate the demographic differences. There are
\Sexpr{sum(features$all_sufficient)} edges where we calculate these
demographic similarities.

<<featureTable, results='asis', message=FALSE>>= 
feature_summary <- data.frame(sufficient.population=c(mean(features$all_sufficient), 
                                rep(NA, 5)),
                              rail = c(mean(features$rail), 
                                rep(NA, 5)),
                              highway = c(mean(features$highway), 
                                rep(NA, 5)),
                              water = c(mean(features$water), 
                                rep(NA, 5)),
                              elementary.school = c(mean(features$elementary_school), 
                                rep(NA, 5)),
                              high.school = c(mean(features$high_school), 
                                rep(NA, 5)),
                              grid.street = c(mean(features$grid_street), 
                                rep(NA, 5)),
                              block.angle=c(mean(features$block_angle), 
                                  quantile(features$block_angle)),
                              diff_units.js=c(mean(features$diff_housing_units[features$all_sufficient==1]), 
                                  
                                quantile(features$diff_housing_units[features$all_sufficient==1])),


                              age.js=c(mean(features$abs_age[features$all_sufficient==1]), 
                                  
                                quantile(features$abs_age[features$all_sufficient==1])),
                              race.js=c(mean(features$chi_ethnicity[features$all_sufficient==1]), 
                                quantile(features$chi_ethnicity[features$all_sufficient==1])),
                              housing.js=c(mean(features$chi_housing[features$all_sufficient==1]), 
                                quantile(features$chi_housing[features$all_sufficient==1])),
                              family.js=c(mean(features$chi_family[features$all_sufficient==1]), 
                                quantile(features$chi_family[features$all_sufficient==1]))
                              
                              )
feature_summary <- xtable(t(feature_summary),
                          caption="Distribution of Barriers and Distances",
                          label="tab:Distribution")
colnames(feature_summary) <- c("Mean", "Min", "25th Quant.", "Median", "75th Quant.", "Max")
row.names(feature_summary) <- c("Sufficient Population", "Rail", "Highway", 
                                "Water", "Elementary School", "High School", 
                                "Grid Street", "Block Angle", 
                                "Log Housing Density", "Log Median Age", 
                                "Ethnicity", "Housing", "Family")
print(feature_summary)
@ 

\begin{figure}
<<railImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$rail + 1])
@ 
\caption{Rail Lines}
\end{figure}

\begin{figure}
<<highwayImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$highway + 1])
@ 
\caption{Highways}
\end{figure}

\begin{figure}
<<gridImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$grid_street + 1])
@ 
\caption{Major Streets}
\end{figure}

\begin{figure}
<<waterImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$water + 1])
@ 
\caption{River}
\end{figure}

\begin{figure}
<<elementaryImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$elementary_school + 1])
@ 
\caption{Elementary School Attendance Boundaries}
\end{figure}

\begin{figure}
<<highschoolImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$high_school + 1])
@ 
\caption{High School Attendance Boundaries}
\end{figure}

\begin{figure}
<<sufficientImage, dev='pdf'>>= 
plot(all_edges$lines, col=c("#00000022", "red")[features$all_sufficient + 1])
@ 
\caption{Sufficient Population}
\end{figure}


\begin{figure}
<<blockAngleImage, dev='pdf'>>= 
plot(all_edges$lines, col=rgb(colorRamp(c("lightgrey", "red"))(features$block_angle)/255))
@ 
\caption{Difference in Block Orientation}
\end{figure}

\begin{figure}
<<<raceImage, dev='pdf'>>=
plot(all_edges$lines[features$all_sufficient==1], col=rgb(colorRamp(c("lightgrey", "red"), space="Lab")(M[,"all_sufficient:chi_ethnicity"][features$all_sufficient==1])/255))
@ 
\caption{Difference in Distribution of Race and Ethnicity}
\end{figure}


\begin{figure}
<<<ageImage, dev='pdf'>>=
plot(all_edges$lines[features$all_sufficient==1], col=rgb(colorRamp(c("lightgrey", "red"), space="Lab")(M[,"all_sufficient:abs_age"][features$all_sufficient==1]/max(M[,"all_sufficient:abs_age"]))/255))
@ 
\caption{Difference in Log Median Age}
\end{figure}


\begin{figure}
<<<housingDiffImage, dev='pdf'>>=
plot(all_edges$lines[features$all_sufficient==1], col=rgb(colorRamp(c("lightgrey", "red"), space="Lab")(M[,"all_sufficient:diff_housing_units"][features$all_sufficient==1]/max(M[,"all_sufficient:diff_housing_units"]))/255))
@ 
\caption{Difference in Log Density of Housing Units}
\end{figure}


\begin{figure}
<<<familyImage, dev='pdf'>>=
plot(all_edges$lines[features$all_sufficient==1], col=rgb(colorRamp(c("lightgrey", "red"), space="Lab")(M[,"all_sufficient:chi_family"][features$all_sufficient==1])/255))
@ 
\caption{Difference in Distribution of Family Type}
\end{figure}


\begin{figure}
<<<housingImage, dev='pdf'>>=
plot(all_edges$lines[features$all_sufficient==1], col=rgb(colorRamp(c("lightgrey", "red"), space="Lab")(M[,"all_sufficient:chi_housing"][features$all_sufficient==1])/255))
@ 
\caption{Difference in Distribution of Housing Type}
\end{figure}

\section*{Modeling}
Since many census blocks are empty, the demographic similarity between
these blocks is not well defined. We might be tempted to ignore these
cases, but deleting these cases would change the topology of the
city. Removing unpopulated blocks would turn populated blocks into
islands separated by commercial corridors. This would not allow for a
neighborhood to span a highway or industrial corridor, a possibility
we do not want to preclude.

We deal with this variation by using dummy variables to effectively
learn two model at once: a nonpopulated and populated block model:

Our overall scoring function is 
\begin{align}
&\operatorname{E}(\mathbf{y}, \mathbf{s}, \mathbf{w}) = \sum_{<i
    j>}^{\mathcal{N}}\epsilon_{i,j}(y_i, y_j, \mathbf{s}_{i,j}, \mathbf{w})  
\end{align}

where 
\begin{equation}
\epsilon_{i,j}(y_i, y_j, \mathbf{s}_{i,j}, \mathbf{w}) = \begin{cases}
    0 \quad\quad\quad y_i = y_j \\
    \phi(\mathbf{s}_{i,j}, \mathbf{w}) \quad y_i \neq y_j \\
  \end{cases}
\end{equation}

and the unpopulated block model is 
\begin{align}
\phi(\mathbf{s}_{i,j}, \mathbf{w}) = & w_0 
                                     + w_1\text{Rail}_{i,j} 
                                     + w_2\text{Water}_{i,j} 
                                     + w_3\text{Highway}_{i,j} \\
                                     &+ w_4\text{Major Street}_{i,j} 
                                     + w_5\text{Elementary School}_{i,j}\\ 
                                     & + w_6\text{High School}_{i,j}
                                     + w_7\text{Block Angle}_{i,j} \\
\end{align}

While the model for the populated neighboring blocks will be

\begin{align}
\phi(\mathbf{s}_{i,j}, \mathbf{w}) = & w_8 
                                     + w_9\text{Rail}_{i,j} 
                                     + w_{10}\text{Water}_{i,j} 
                                     + w_{11}\text{Highway}_{i,j}\\
                                     &+ w_{12}\text{Major Street}_{i,j} 
                                     + w_{13}\text{Elementary School}_{i,j}\\
                                     &+ w_{14}\text{High School}_{i,j} 
                                     + w_{15}\text{Block Angle}_{i,j}\\
                                     &+ w_{16}\text{Family Structure}_{i,j}
                                     + w_{17}\text{Race and Ethnicity}_{i,j}\\
                                     &+ w_{18}\text{Age Structure}_{i,j}  
                                     + w_{19}\text{Housing Structure}_{i,j} \\
                                     &+ w_{20}\text{Housing Density}_{i,j}  
\end{align}

We can combine these models by creating a dummy variable that takes a
value of 1 if neighboring block have sufficient population to support
the demographic distance measures, and 0 if the neighboring blocks do
not. We'll interact this dummy with the populated model and add the
variables to our unpopulated model.\footnote{Actually, our model is
  a little more complicated because we are not just comparing
  groups of people, but also groups of households and groups of
  housing units. Sometimes there is sufficient population to compare
  race, but not sufficient households to compare family structure. We
  use an additional dummy variables to handle these cases}

\begin{align}
\phi(\mathbf{s}_{i,j}, \mathbf{w}) =  & w_0 
                                     + w_1\text{Rail}_{i,j} 
                                     + w_2\text{Water}_{i,j} 
                                     + w_3\text{Highway}_{i,j} \\
                                     &+ w_4\text{Major Street}_{i,j} 
                                     + w_5\text{Elementary School}_{i,j}\\ 
                                     & + w_6\text{High School}_{i,j}
                                     + w_7\text{Block Angle}_{i,j} \\
                                     &+ \text{Populated Blocks}_{i,j}\cdot\\
                                     &\quad (w_8
                                     + w_{9}\text{Rail}_{i,j} 
                                     + w_{10}\text{Water}_{i,j}\\ 
                                     &\quad+ w_{11}\text{Highway}_{i,j}
                                     + w_{12}\text{Major Street}_{i,j}\\ 
                                     &\quad + w_{13}\text{Elementary School}_{i,j} 
                                     + w_{14}\text{High School}_{i,j}\\ 
                                     &\quad + w_{15}\text{Block Angle}_{i,j}
                                     + w_{16}\text{Family Structure}_{i,j}\\
                                     &\quad + w_{17}\text{Race and Ethnicity}_{i,j}
                                     + w_{18}\text{Age Structure}_{i,j}\\  
                                     &\quad+ w_{19}\text{Housing Structure}_{i,j}
                                     + w_{20}\text{Housing Density}_{i,j})\\
\end{align}


\section*{Results}
After training the model using the PyStruct structure learning
framework,\cite{mueller_pystruct:_????} we get two classes of results:
predictions of Chicago neighborhoods and parameter
estimates.\footnote{See \url{https://github.com/fgregg/pystruct} for
  custom model}

Given a set of learned weights we can find, approximately, a lowest
scoring assignment of labels to neighborhoods of the city. However,
some care must be taken to not immediately assign meaning to these
labelings. Two blocks that have been assigned that same label do not
necessarily belong to the same neighborhood. The labelings are only
locally meaningful in that they distinguish a particular neighborhood
from it’s neighbors. Instead, a neighborhood will be a set of block
that have the same label and which are connected components.  

Let’s start by looking at predictions for our training blocks to
highlight some characteristics of our model (Figure
\ref{fig:predictTraining}).

\begin{figure}
<<plotPredictions, echo=FALSE, dev='pdf', message=FALSE>>=
par(mfrow=c(1,2))
par(mar=rep(0, 4), xpd = NA) 
source('plot_training.R')
setwd('../code/training/')
source('plot_predictions.R')
setwd(CURDIR)
par(mfrow=c(1,1))
@ 
\caption{Predicted Neighborhoods}
\label{fig:predictTraining}
\end{figure}

<<RandIndex>>=

library(phyclust)
training_neighborhoods <- read.csv("../code/interchange/ks_label_semantic.csv")$x
infrequent <- hood_frequency[hoods] < 10
rand <- phyclust::RRand(hoods[!infrequent], training_neighborhoods[!infrequent])
@ 

First, our model depends upon C, the normalizer.  C. We choose C by
estimating the model for various values of C between 1.0 and 0.0001
and choosing the value that maximizes the fit between the predicted
neighborhoods and the training neighborhoods. The value of C that gave
the best fit was 0.0005.

Second, our model predicts many, very small neighborhoods. In Figure
\ref{fig:predictTraining}, I have colored the
\Sexpr{sum(hood_frequency >= 10)} neighborhoods that have ten or more
blocks and grayed out the \Sexpr{sum(hood_frequency < 10)} remaining,
small neighborhoods. There are \Sexpr{sum(hood_frequency ==1)}
neighborhoods that consist of a single block.

Third, our model seems to do an adequate job in capturing
neighborhoods. We have a Rand Index score of \Sexpr{formatC(rand$Rand, format="f", digits=2)} and an
Adjusted Rand of \Sexpr{formatC(rand$adjRand, format="f", digits=2)}.

Now, turning to the parameters, we'll focus on the parameters for the
populated blocks (Table \ref{tab:parameters}). A positive parameter
means that, all else equal, the total score will be lower if adjacent
blocks are allocated to separate neighborhoods. Negative parameters,
means that all else equal, adjacent blocks should be allocated to the
same neighborhood. So, for example the negative intercepts mean that
adjacent blocks that are identical will ‘prefer’ to be assigned to the
same neighborhood.

Nearly all parameters for barriers and administrative zones have a
positive sign, which is what we expect: dissimilar blocks and blocks
separated by barriers are more apt to be placed in separate
neighborhoods. The negative `attractive' parameter for major street is
likely due to fact that every one of our training neighborhoods
contains multiple major grid streets.

The demographic distances are more complicated. Differences in ethnic
and racial composition is strongly positive. Such a `divisive'
parameter is required to have face validity in Chicago. Differences in
the density of housing units also has the expected sign. Differences
in median age and housing structure are unexpectedly weak, but also
very close to 0. The relatively strong `attractive' parameter for
differences in family structure is very surprising. According the this
model, a block that is all families and a block that has no families
are very apt to belong the same neighborhood. 

<<weightTable, results='asis', cache=FALSE>>=
setwd('../code/training/')
weights <- read.table("weights.csv")
names(weights) <- colnames(M)

no_pop <- c(weights[c('(Intercept)', 
                      'rail', 
                      'water',
                      'highway', 
                      'grid_street', 
                      'elementary_school', 
                      'high_school', 
                      'block_angle')])

pop <- c(weights[c('all_sufficient', 
                   'all_sufficient:rail', 
                   'all_sufficient:water',
                   'highway',
                   'all_sufficient:grid_street', 
                   'all_sufficient:elementary_school', 
                   'all_sufficient:high_school', 
                   'all_sufficient:block_angle')])
pop$highway <- 0

combined_pop <- c(as.numeric(pop) 
                  + as.numeric(no_pop), 
                  weights[c('all_sufficient:chi_family', 
                            'all_sufficient:chi_ethnicity', 
                            'all_sufficient:abs_age',
                            'all_sufficient:diff_housing_units',
                            'all_sufficient:chi_housing')])


models <- matrix(combined_pop)

rownames(models) <- c('(Intercept)', 
                      'Railroad', 
                      'Water', 
                      'Highway', 
                      'Major Street', 
                      'Elementary School', 
                      'High School', 
                      'Block Angle', 
                      'Family Structure', 
                      'Race and Ethnicity', 
                      'Age Structure', 
                      'Density of Housing Units',
                      'Housing Structure')

WT <- xtable(models, digits=4,
             caption="Parameter Estimates for Populated Blocks",
             label="tab:parameters")
colnames(WT) <- c("")

print(WT)

@ 

\section*{Discussion}
While these results of modeling neighborhoods are interesting, we
should take care to not put too much weight in them yet. Our purpose
in this paper is to explore an \emph{approach} to modeling what counts
for similarity and to evaluate if our models are adequate to capturing
observed social groupings. 

What we have established is that this model of neighborhoods seems to
be able to predict, with some fidelity, the training data, and that
the parameter values comport with our previous expectations. These
results should give us confidence that the modeling approach can
capture the pheonomena. 

However, in order to learn from the model or extrapolate it's
predictions beyond the training data, this approach must pass much
more rigorous tests than simply predicting the training data for one
city. In a future paper, I will use this approach to model
neighborhoods in the fifty largest American urban areas, and evaluate
the predictive power of this conception of neighborhoods. 

In future work, we could use the same types of models to learn about
the structures of intra-party factions through looking at campaign
giving or social class-like structure by looking at marriage
patterns. Much of this work will depend upon being able to validly
distinguish between proximity and similarity. In cities, its easy to
do this. In other areas of social research, it's not so simple to
distinguish between the two.


\bibliographystyle{plain}
\bibliography{qp}

\begin{figure}
\includegraphics{../code/training/predicted_chicago_neighborhoods.pdf}
\caption{Predicted Neighborhoods in Chicago}
\end{figure}


\end{document}
